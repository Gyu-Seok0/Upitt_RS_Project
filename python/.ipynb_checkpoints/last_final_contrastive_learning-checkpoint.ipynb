{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f4eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import easydict\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.mapper import HinSAGELinkGenerator\n",
    "from stellargraph.layer import HinSAGE, link_classification\n",
    "from utils import *\n",
    "\n",
    "from tensorflow.keras import Model, optimizers, losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11f4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "        \"data_path\" : \"./Dataset/Total\",\n",
    "        \"emb_path\" : \"./Result_for_embedding/Total/Loss_1.2758\",\n",
    "        \"result_path\" : \"./Result_for_HinSage/Total\",\n",
    "        \"weight_toggle\" : False,\n",
    "        \"num_folds\" : 5,\n",
    "        \"num_samples\" : [4,2],\n",
    "        \"layer_sizes\" : [16,8],\n",
    "        \"batch_size\" : 1000,\n",
    "        \"epochs\" : 100,\n",
    "        \"lr\" : 0.001,\n",
    "        \"drop_out\" : 0.4,\n",
    "        \"num_workers\" : -1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7c69db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_csv = 77, num_wiki = 2512\n",
      "edge_df.shape = (8120, 2)\n",
      "\n",
      "[After applying drop_duplicate]\n",
      "edge_df.shape = (7237, 2)\n",
      "\n",
      "[After applying rename_for_value]\n",
      "      csv       wiki\n",
      "0  csv-26  wiki-2327\n",
      "1  csv-26  wiki-1312\n",
      "2  csv-26  wiki-1278\n",
      "3  csv-26  wiki-1241\n",
      "4  csv-26   wiki-913\n",
      "node_csv =             0         1         2         3         4         5         6    \\\n",
      "csv-0 -0.240582 -0.096518 -0.204321 -0.057264  0.130768 -0.063019  0.180385   \n",
      "csv-1  0.033454  0.065465  0.428110 -0.113888  0.536284 -0.092917  0.170378   \n",
      "csv-2 -0.210087 -0.152295  0.210778 -0.025063  0.449653  0.291625  0.071882   \n",
      "csv-3 -0.266294  0.060738 -0.420196  0.443523  0.224524 -0.249679  0.490691   \n",
      "csv-4  0.253309  0.038146  0.021372  0.101454 -0.286800  0.230597 -0.146937   \n",
      "\n",
      "            7         8         9    ...       118       119       120  \\\n",
      "csv-0  0.001783  0.212850  0.051950  ... -0.153015 -0.027282 -0.037565   \n",
      "csv-1  0.053746  0.079655  0.144963  ... -0.077511 -0.286580 -0.161355   \n",
      "csv-2  0.155274  0.048890 -0.120483  ... -0.166836 -0.056385 -0.097589   \n",
      "csv-3  0.247115 -0.012336  0.490024  ...  0.131347 -0.212784 -0.268399   \n",
      "csv-4 -0.006975  0.118955  0.320258  ...  0.006333 -0.079114  0.090220   \n",
      "\n",
      "            121       122       123       124       125       126       127  \n",
      "csv-0 -0.110901  0.215168  0.364613 -0.102798 -0.348406 -0.259555  0.018591  \n",
      "csv-1 -0.111309  0.082875  0.234833 -0.214153 -0.169364  0.332148 -0.050171  \n",
      "csv-2  0.147075  0.320355 -0.292478 -0.064677 -0.147436  0.216158  0.249005  \n",
      "csv-3  0.538113  0.893442  0.445640 -0.283187 -0.333214  0.604226  0.463532  \n",
      "csv-4  0.011318  0.113630  0.001420 -0.286978  0.247812  0.028229  0.103963  \n",
      "\n",
      "[5 rows x 128 columns]\n",
      "node_wiki =              0         1         2         3         4         5         6    \\\n",
      "wiki-0  0.527034 -0.116147 -0.184775 -0.061609  0.468074  0.282656  0.131014   \n",
      "wiki-1 -0.684858 -0.055441 -0.221970  0.459947  0.128692 -0.429269 -0.091643   \n",
      "wiki-2  0.061288 -0.257040  0.115948  0.160993 -0.017914 -0.263516  0.228586   \n",
      "wiki-3 -0.018664  0.057175  0.037046  0.071865 -0.587055  0.191193  0.064318   \n",
      "wiki-4 -0.425923 -0.186989  0.494927 -0.028550 -0.231580  0.135106 -0.053956   \n",
      "\n",
      "             7         8         9    ...       118       119       120  \\\n",
      "wiki-0  0.405856  0.221405  0.265950  ... -0.208398 -0.492606 -0.331774   \n",
      "wiki-1  0.083454 -0.200478  0.579340  ... -0.180787  0.121831  0.070580   \n",
      "wiki-2 -0.511468  0.068159  0.664377  ... -0.518391 -0.061033 -0.197004   \n",
      "wiki-3 -0.213340 -0.047722  0.594818  ...  0.251053 -0.267337  0.224664   \n",
      "wiki-4  0.186308  0.526836 -0.016336  ... -0.264073 -0.111578 -0.207020   \n",
      "\n",
      "             121       122       123       124       125       126       127  \n",
      "wiki-0  0.191482 -0.471675 -0.036320 -0.223525 -0.052506  0.351547  0.414022  \n",
      "wiki-1 -0.131899  0.252825 -0.279311 -0.383983 -0.158082  0.595816  0.035571  \n",
      "wiki-2 -0.254271  0.901781 -0.263141 -0.257262  0.051308  0.350465 -0.450217  \n",
      "wiki-3  0.106271 -0.093117  0.221750 -0.388597  0.250632  0.003541  0.262093  \n",
      "wiki-4  0.010371  0.313755 -0.599814 -0.106207 -0.151935  0.051264 -0.200198  \n",
      "\n",
      "[5 rows x 128 columns]\n",
      "\n",
      "[Graph]\n",
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 2589, Edges: 7237\n",
      "\n",
      " Node types:\n",
      "  wiki: [2512]\n",
      "    Features: float32 vector, length 128\n",
      "    Edge types: wiki-default->csv\n",
      "  csv: [77]\n",
      "    Features: float32 vector, length 128\n",
      "    Edge types: csv-default->wiki\n",
      "\n",
      " Edge types:\n",
      "    csv-default->wiki: [7237]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "Network has 7237 edges of type default\n",
      "Network has 7237 edges of type default\n",
      "** Sampled 144 positive and 144 negative edges. **\n",
      "Network has 7093 edges of type default\n",
      "Network has 7093 edges of type default\n",
      "** Sampled 148 positive and 148 negative edges. **\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "wiki2csv = load_pickle(os.path.join(args.data_path,\"wiki2csv\"))\n",
    "csv2wiki = load_pickle(os.path.join(args.data_path,\"csv2wiki\"))\n",
    "embedding = load_pickle(os.path.join(args.emb_path,\"Embedding\"))\n",
    "num_csv = len(csv2wiki.keys())\n",
    "num_wiki = len(wiki2csv.keys())\n",
    "print(f\"num_csv = {num_csv}, num_wiki = {num_wiki}\")\n",
    "\n",
    "graph = make_graph(csv2wiki, embedding, num_csv, args)\n",
    "G_train, edge_ids_train, edge_labels_train, G_test, edge_ids_test, edge_labels_test = train_test_graph_split(graph)\n",
    "\n",
    "head_node_types = [\"wiki\",\"csv\"]\n",
    "if edge_ids_train[0][0].find(\"csv\") >= 0:\n",
    "    head_node_types = [\"csv\", \"wiki\"]\n",
    "    \n",
    "train_gen = make_generate(G_train, head_node_types, args)\n",
    "train_flow = train_gen.flow(edge_ids_train, edge_labels_train, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b717b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "cad4c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = \"gyusoek\"\n",
    "temp2 = \"jihu\"\n",
    "\n",
    "def make_Tesla():\n",
    "    #temp1 = \"a\"\n",
    "    #temp2 = \"b\"\n",
    "    class Tesla:\n",
    "        global temp1,temp3\n",
    "\n",
    "        def printout(self):\n",
    "            print(temp1,temp3)\n",
    "    \n",
    "    return Tesla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "088af9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyusoek ji\n"
     ]
    }
   ],
   "source": [
    "temp1 = \"gyusoek\"\n",
    "temp3 = \"ji\"\n",
    "c = make_Tesla()\n",
    "\n",
    "c.printout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ce889554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyusoek jihu\n"
     ]
    }
   ],
   "source": [
    "c = Tesla()\n",
    "c.printout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee6c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d2a459ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow\n",
    "temperature = 1\n",
    "a1 = 0.05\n",
    "a2 = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805dea2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "4a1458fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    global train_flow, temperature, a1, a2\n",
    "    \n",
    "    def get_loss(self, f1, f2, train_flow, temperature):\n",
    "\n",
    "        #f1, f2 = x_out[0], x_out[1]\n",
    "        #train_flow.ids\n",
    "        csv_dict = defaultdict(list)\n",
    "        wiki_dict = defaultdict(list)\n",
    "        csv_wiki_map = []\n",
    "        csv_id_mapping = {}\n",
    "        wiki_id_mapping = {}\n",
    "        csv_wiki_id_matching = []\n",
    "\n",
    "        for idx, (csv_id, wiki_id) in enumerate(train_flow.ids):\n",
    "            csv_dict[csv_id].append(f1[idx])\n",
    "            wiki_dict[wiki_id].append(f2[idx])\n",
    "\n",
    "            if csv_id not in csv_id_mapping.keys():\n",
    "                csv_id_mapping[csv_id] = len(csv_id_mapping)\n",
    "\n",
    "            if wiki_id not in wiki_id_mapping.keys():\n",
    "                wiki_id_mapping[wiki_id] = len(wiki_id_mapping)\n",
    "\n",
    "            mapping_id_csv = csv_id_mapping[csv_id]\n",
    "            mapping_id_wiki = wiki_id_mapping[wiki_id]\n",
    "\n",
    "            csv_wiki_id_matching.append((mapping_id_csv, mapping_id_wiki))\n",
    "\n",
    "        csv_wiki_map = [[0] * len(wiki_dict) for _ in range(len(csv_dict))]\n",
    "\n",
    "        for row,col in csv_wiki_id_matching:\n",
    "            csv_wiki_map[row][col] = 1\n",
    "\n",
    "        csv_wiki_map = tf.convert_to_tensor(csv_wiki_map)\n",
    "\n",
    "        csv_embeddings = []\n",
    "        for value in list(csv_dict.values()):\n",
    "            csv_embeddings.append(tf.math.reduce_mean(tf.convert_to_tensor(value), axis = 0))\n",
    "        csv_embeddings = tf.convert_to_tensor(csv_embeddings)\n",
    "\n",
    "        wiki_embeddings = []\n",
    "        for value in list(wiki_dict.values()):\n",
    "            wiki_embeddings.append(tf.math.reduce_mean(tf.convert_to_tensor(value), axis = 0))\n",
    "        wiki_embeddings = tf.convert_to_tensor(wiki_embeddings)\n",
    "\n",
    "        mm_result = tf.divide(tf.matmul(csv_embeddings, tf.transpose(wiki_embeddings)), temperature)\n",
    "\n",
    "        exp_mm_result = tf.exp(mm_result)\n",
    "\n",
    "        sum_mm_result = tf.math.reduce_sum(exp_mm_result, axis = 1)\n",
    "        normalized_result = tf.math.log(tf.divide(exp_mm_result, tf.expand_dims(sum_mm_result, axis = 1)))\n",
    "        csv_wiki_map = tf.cast(csv_wiki_map, dtype = tf.float32)\n",
    "        masked_result = tf.math.multiply(normalized_result, csv_wiki_map)\n",
    "        axis1_loss = -tf.reduce_mean(tf.reduce_sum(masked_result, axis = 1) / tf.reduce_sum(csv_wiki_map, axis = 1))\n",
    "\n",
    "        sum_mm_result = tf.math.reduce_sum(exp_mm_result, axis = 0)\n",
    "        normalized_result = tf.math.log(tf.divide(exp_mm_result, tf.expand_dims(sum_mm_result, axis = 0)))\n",
    "        masked_result = tf.math.multiply(normalized_result, csv_wiki_map)\n",
    "        axis0_loss = -tf.reduce_mean(tf.reduce_sum(masked_result, axis = 0) / tf.reduce_sum(csv_wiki_map, axis = 0))\n",
    "        \n",
    "        return (axis0_loss, axis1_loss)\n",
    "        \n",
    "\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        sample_weight = None\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_out = self(x, training=True)\n",
    "            print(\"x\",x)\n",
    "            f1, f2 = x_out[0], x_out[1]\n",
    "            \n",
    "            y_pred = tf.sigmoid(tf.reduce_sum(f1 * f2, axis = 1))\n",
    "            \n",
    "            print(\"x_out\", x_out)\n",
    "            print(\"y_pred\", y_pred)\n",
    "            \n",
    "            axis0_loss, axis1_loss = self.get_loss(f1, f2, train_flow, temperature)\n",
    "            bce_loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "                        \n",
    "            loss = bce_loss + a1*axis0_loss + a2*axis1_loss\n",
    "            \n",
    "            acc = tf.reduce_mean(tf.cast(tf.where(tf.greater(y_pred, 0.5), 1,0) == ans, dtype = tf.int32))\n",
    "\n",
    "            \n",
    "#             f1,f2,link_prediction = y_pred[0][0], y_pred[0][1], y_pred[1] \n",
    "#             print(\"f1,f2,link_prediction\",f1,f2,link_prediction)\n",
    "            \n",
    "#             loss = losses.binary_crossentropy(y, link_prediction)\n",
    "#             print(\"loss\", loss)\n",
    "#             cont_loss = self.loss_fn(y_pred, self.train_flow, temperature)\n",
    "#             print(\"cont_loss\",cont_loss)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics.\n",
    "        # Metrics are configured in `compile()`.\n",
    "        #self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n",
    "\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        #result = {m.name: m.result() for m in self.metrics}\n",
    "        result = dict()\n",
    "        result[\"Total_loss\"] = loss\n",
    "        result[\"Contrastive_loss(axis0)\"] = axis0_loss\n",
    "        result[\"Contrastive_loss(axis1)\"] = axis1_loss\n",
    "        result[\"Bce_loss\"] = bce_loss\n",
    "        result[\"Train_acc\"] = acc\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        x_out = self(x, training=True)\n",
    "        f1, f2 = x_out[0], x_out[1]\n",
    "            \n",
    "        y_pred = tf.sigmoid(tf.reduce_sum(f1 * f2, axis = 1))\n",
    "        \n",
    "        acc = tf.reduce_mean(tf.cast(tf.where(tf.greater(y_pred, 0.5), 1,0) == ans, dtype = tf.int32))\n",
    "        bce_loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        \n",
    "        result = {}\n",
    "        result[\"Acc\"] = acc\n",
    "        result[\"Loss\"] = bce_loss\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "e16f80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Contrastive_Model(keras.Model):\n",
    "    def __init__(self, train_flow, temperature, a0, a1, inputs, outputs):\n",
    "        super().__init__()\n",
    "        self.train_flow = None\n",
    "        self.temperature = None\n",
    "        self.a0 = None\n",
    "        self.a1 = None\n",
    "        self.model = Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "    \n",
    "    def call(self, data):\n",
    "        return self.model(data)\n",
    "\n",
    "    #global train_flow, temperature, a0, a1\n",
    "    \n",
    "    def get_loss(self, f1, f2, train_flow, temperature):\n",
    "\n",
    "        csv_dict = defaultdict(list)\n",
    "        wiki_dict = defaultdict(list)\n",
    "        csv_wiki_map = []\n",
    "        csv_id_mapping = {}\n",
    "        wiki_id_mapping = {}\n",
    "        csv_wiki_id_matching = []\n",
    "\n",
    "        for idx, (csv_id, wiki_id) in enumerate(train_flow.ids):\n",
    "            csv_dict[csv_id].append(f1[idx])\n",
    "            wiki_dict[wiki_id].append(f2[idx])\n",
    "\n",
    "            if csv_id not in csv_id_mapping.keys():\n",
    "                csv_id_mapping[csv_id] = len(csv_id_mapping)\n",
    "\n",
    "            if wiki_id not in wiki_id_mapping.keys():\n",
    "                wiki_id_mapping[wiki_id] = len(wiki_id_mapping)\n",
    "\n",
    "            mapping_id_csv = csv_id_mapping[csv_id]\n",
    "            mapping_id_wiki = wiki_id_mapping[wiki_id]\n",
    "\n",
    "            csv_wiki_id_matching.append((mapping_id_csv, mapping_id_wiki))\n",
    "\n",
    "        csv_wiki_map = [[0] * len(wiki_dict) for _ in range(len(csv_dict))]\n",
    "\n",
    "        for row,col in csv_wiki_id_matching:\n",
    "            csv_wiki_map[row][col] = 1\n",
    "\n",
    "        csv_wiki_map = tf.convert_to_tensor(csv_wiki_map)\n",
    "\n",
    "        csv_embeddings = []\n",
    "        for value in list(csv_dict.values()):\n",
    "            csv_embeddings.append(tf.math.reduce_mean(tf.convert_to_tensor(value), axis = 0))\n",
    "        csv_embeddings = tf.convert_to_tensor(csv_embeddings)\n",
    "\n",
    "        wiki_embeddings = []\n",
    "        for value in list(wiki_dict.values()):\n",
    "            wiki_embeddings.append(tf.math.reduce_mean(tf.convert_to_tensor(value), axis = 0))\n",
    "        wiki_embeddings = tf.convert_to_tensor(wiki_embeddings)\n",
    "\n",
    "        mm_result = tf.divide(tf.matmul(csv_embeddings, tf.transpose(wiki_embeddings)), temperature)\n",
    "\n",
    "        exp_mm_result = tf.exp(mm_result)\n",
    "\n",
    "        sum_mm_result = tf.math.reduce_sum(exp_mm_result, axis = 1)\n",
    "        normalized_result = tf.math.log(tf.divide(exp_mm_result, tf.expand_dims(sum_mm_result, axis = 1)))\n",
    "        csv_wiki_map = tf.cast(csv_wiki_map, dtype = tf.float32)\n",
    "        masked_result = tf.math.multiply(normalized_result, csv_wiki_map)\n",
    "        axis1_loss = -tf.reduce_mean(tf.reduce_sum(masked_result, axis = 1) / tf.reduce_sum(csv_wiki_map, axis = 1))\n",
    "\n",
    "        sum_mm_result = tf.math.reduce_sum(exp_mm_result, axis = 0)\n",
    "        normalized_result = tf.math.log(tf.divide(exp_mm_result, tf.expand_dims(sum_mm_result, axis = 0)))\n",
    "        masked_result = tf.math.multiply(normalized_result, csv_wiki_map)\n",
    "        axis0_loss = -tf.reduce_mean(tf.reduce_sum(masked_result, axis = 0) / tf.reduce_sum(csv_wiki_map, axis = 0))\n",
    "        \n",
    "        return (axis0_loss, axis1_loss)\n",
    "        \n",
    "\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        sample_weight = None\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward\n",
    "            x_out = self(x, training=True)\n",
    "            f1, f2 = x_out[0], x_out[1]\n",
    "            y_pred = tf.sigmoid(tf.reduce_sum(f1 * f2, axis = 1))\n",
    "            \n",
    "            # Loss\n",
    "            axis0_loss, axis1_loss = self.get_loss(f1, f2)\n",
    "            bce_loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "            loss = bce_loss + a0 * axis0_loss + a1 * axis1_loss\n",
    "\n",
    "            # Acc\n",
    "            y = tf.cast(y, dtype = tf.float32)\n",
    "            acc = tf.reduce_mean(tf.cast(tf.where(tf.greater(y_pred, 0.5), 1,0) == y, dtype = tf.float32))\n",
    "\n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics.\n",
    "        result = dict()\n",
    "        result[\"Total_loss\"] = loss\n",
    "        result[\"Contrastive_loss(axis0)\"] = axis0_loss\n",
    "        result[\"Contrastive_loss(axis1)\"] = axis1_loss\n",
    "        result[\"Bce_loss\"] = bce_loss\n",
    "        result[\"Train_acc\"] = acc\n",
    "        return result\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        # forward\n",
    "        x, y = data\n",
    "        x_out = self(x, training=True)\n",
    "        f1, f2 = x_out[0], x_out[1]            \n",
    "        y_pred = tf.sigmoid(tf.reduce_sum(f1 * f2, axis = 1))\n",
    "\n",
    "\n",
    "        y = tf.cast(y, dtype = tf.float32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.where(tf.greater(y_pred, 0.5), 1.0, 0.0) == y, dtype = tf.float32))\n",
    "        bce_loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        \n",
    "        # save\n",
    "        result = {}\n",
    "        result[\"Acc\"] = acc\n",
    "        result[\"Loss\"] = bce_loss\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c198c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "266a566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, train_flow, temperature = 1):\n",
    "        super().__init__()\n",
    "        self.train_flow = train_flow\n",
    "        self.temperature = temperature\n",
    "        self.BCE = losses.BinaryCrossentropy()\n",
    "        \n",
    "    def __call__(self, y_true, x_out, sample_weight = None):\n",
    "        f1, f2 = x_out[0], x_out[1]\n",
    "        print(\"x_out\",x_out)\n",
    "        print(\"f1\",f1)\n",
    "        print(\"f2\",f2)\n",
    "        y_pred = tf.sigmoid(tf.reduce_sum(f1 * f2, axis = 1))\n",
    "\n",
    "        BCELoss = self.BCE(y_true, link_prediction)\n",
    "        \n",
    "        return BCELoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "76f7db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hinsage = HinSAGE(\n",
    "                  layer_sizes = [32,8],\n",
    "                  generator = train_gen,\n",
    "                  bias = True,\n",
    "                  dropout = 0.4\n",
    "                  )\n",
    "x_inp, x_out = hinsage.in_out_tensors()\n",
    "#link_prediction = link_classification(edge_embedding_method = \"ip\")(x_out) # ip = inner proudct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "2bfa166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_flow\n",
    "temperature = 1\n",
    "a0 = 0.5\n",
    "a1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "47ad0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = CustomModel(inputs = x_inp,\n",
    "#                 outputs = x_out)\n",
    "\n",
    "m = Contrastive_Model(train_flow, temperature, a0, a1, x_inp, x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "3f2e9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer=\"adam\", metrics = metrics.binary_accuracy, loss = losses.binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "0d7d54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_flow))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "3642bcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(296, 8), dtype=float32, numpy=\n",
       " array([[-0.04713205,  0.26990375, -0.6513013 , ...,  0.22586267,\n",
       "         -0.58364195,  0.02282516],\n",
       "        [ 0.58535767,  0.3322697 , -0.4314093 , ..., -0.18428473,\n",
       "          0.18784504,  0.39991847],\n",
       "        [-0.42524377,  0.07696816, -0.42189527, ..., -0.341557  ,\n",
       "         -0.40785927,  0.56711036],\n",
       "        ...,\n",
       "        [ 0.61131155, -0.15258178,  0.07643192, ..., -0.5386778 ,\n",
       "         -0.07623275,  0.48107812],\n",
       "        [ 0.50570804,  0.4610584 ,  0.1768859 , ..., -0.08998042,\n",
       "         -0.1390052 ,  0.5470961 ],\n",
       "        [ 0.6779684 , -0.0197721 ,  0.44432622, ..., -0.16691458,\n",
       "         -0.41810396,  0.26558116]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(296, 8), dtype=float32, numpy=\n",
       " array([[-0.36071363,  0.3417938 ,  0.6488096 , ...,  0.41094124,\n",
       "         -0.05233214,  0.1799484 ],\n",
       "        [ 0.22127463,  0.43573296, -0.13377467, ...,  0.47175932,\n",
       "         -0.21856877,  0.5203732 ],\n",
       "        [-0.11854365,  0.26112962, -0.27987725, ...,  0.259963  ,\n",
       "          0.2268057 ,  0.29913878],\n",
       "        ...,\n",
       "        [ 0.24345072,  0.1588821 , -0.36814573, ...,  0.59121376,\n",
       "          0.2848141 ,  0.28792584],\n",
       "        [ 0.6484792 ,  0.21971835, -0.17577337, ..., -0.1577585 ,\n",
       "         -0.22354008,  0.21123464],\n",
       "        [ 0.34158564,  0.320746  , -0.40069762, ...,  0.3552726 ,\n",
       "         -0.21631624,  0.63902134]], dtype=float32)>]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6927bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "54c1a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-463-fe02651c86e8>:86 train_step\n        axis0_loss, axis1_loss = self.get_loss(f1, f2, self.train_flow, self.temperature)\n    <ipython-input-463-fe02651c86e8>:25 get_loss\n        for idx, (csv_id, wiki_id) in enumerate(train_flow.ids):\n\n    AttributeError: 'NoneType' object has no attribute 'ids'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-470-179484de17dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_flow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_flow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-463-fe02651c86e8>:86 train_step\n        axis0_loss, axis1_loss = self.get_loss(f1, f2, self.train_flow, self.temperature)\n    <ipython-input-463-fe02651c86e8>:25 get_loss\n        for idx, (csv_id, wiki_id) in enumerate(train_flow.ids):\n\n    AttributeError: 'NoneType' object has no attribute 'ids'\n"
     ]
    }
   ],
   "source": [
    "result = m.fit(train_flow, epochs= 100, validation_data = train_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0594aaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6334348320960999,\n",
       "  0.6215649247169495,\n",
       "  0.6307473182678223,\n",
       "  0.6371259093284607,\n",
       "  0.635435163974762,\n",
       "  0.6290022134780884,\n",
       "  0.6279046535491943,\n",
       "  0.6185811161994934,\n",
       "  0.628836989402771,\n",
       "  0.6193700432777405,\n",
       "  0.6214694380760193,\n",
       "  0.6299982070922852,\n",
       "  0.6385582685470581,\n",
       "  0.6190268993377686,\n",
       "  0.6260812878608704,\n",
       "  0.6277178525924683,\n",
       "  0.622283935546875,\n",
       "  0.6132780313491821,\n",
       "  0.6166733503341675,\n",
       "  0.6194484829902649,\n",
       "  0.6176406741142273,\n",
       "  0.6326060891151428,\n",
       "  0.6275089979171753,\n",
       "  0.6137653589248657,\n",
       "  0.6187788844108582,\n",
       "  0.6161745190620422,\n",
       "  0.6077532768249512,\n",
       "  0.6204389333724976,\n",
       "  0.6143245100975037,\n",
       "  0.6279863119125366,\n",
       "  0.6047563552856445,\n",
       "  0.62306147813797,\n",
       "  0.6076730489730835,\n",
       "  0.6151086688041687,\n",
       "  0.609878420829773,\n",
       "  0.6213788390159607,\n",
       "  0.6188862323760986,\n",
       "  0.6092218160629272,\n",
       "  0.6022497415542603,\n",
       "  0.6304208636283875,\n",
       "  0.5963815450668335,\n",
       "  0.6146062016487122,\n",
       "  0.6179717183113098,\n",
       "  0.6021655201911926,\n",
       "  0.6156232357025146,\n",
       "  0.5926353335380554,\n",
       "  0.5990211963653564,\n",
       "  0.593015193939209,\n",
       "  0.6058152914047241,\n",
       "  0.6028765439987183,\n",
       "  0.5950760245323181,\n",
       "  0.6138789653778076,\n",
       "  0.6023572683334351,\n",
       "  0.6069602966308594,\n",
       "  0.5996020436286926,\n",
       "  0.600838303565979,\n",
       "  0.5939256548881531,\n",
       "  0.6103895306587219,\n",
       "  0.6030519604682922,\n",
       "  0.5981308221817017,\n",
       "  0.6060734987258911,\n",
       "  0.6086366176605225,\n",
       "  0.6066993474960327,\n",
       "  0.5955371260643005,\n",
       "  0.6003330945968628,\n",
       "  0.5939992070198059,\n",
       "  0.5823036432266235,\n",
       "  0.5984122157096863,\n",
       "  0.5906094312667847,\n",
       "  0.5954869985580444,\n",
       "  0.5861852169036865,\n",
       "  0.5806572437286377,\n",
       "  0.6050789952278137,\n",
       "  0.6098224520683289,\n",
       "  0.5953585505485535,\n",
       "  0.5969748497009277,\n",
       "  0.5860665440559387,\n",
       "  0.5800647139549255,\n",
       "  0.5967372059822083,\n",
       "  0.5893594026565552,\n",
       "  0.5892736911773682,\n",
       "  0.5863004922866821,\n",
       "  0.5869585275650024,\n",
       "  0.5909066200256348,\n",
       "  0.5847674608230591,\n",
       "  0.5856451392173767,\n",
       "  0.5757430195808411,\n",
       "  0.5963168740272522,\n",
       "  0.5783886313438416,\n",
       "  0.5815064907073975,\n",
       "  0.5842541456222534,\n",
       "  0.592023491859436,\n",
       "  0.5783593654632568,\n",
       "  0.5737311840057373,\n",
       "  0.5747944116592407,\n",
       "  0.5727208256721497,\n",
       "  0.5704395771026611,\n",
       "  0.5680650472640991,\n",
       "  0.5897600054740906,\n",
       "  0.5725669860839844],\n",
       " 'lambda_40_loss': [0.6334348320960999,\n",
       "  0.6215649247169495,\n",
       "  0.6307473182678223,\n",
       "  0.6371259093284607,\n",
       "  0.635435163974762,\n",
       "  0.6290022134780884,\n",
       "  0.6279046535491943,\n",
       "  0.6185811161994934,\n",
       "  0.628836989402771,\n",
       "  0.6193700432777405,\n",
       "  0.6214694380760193,\n",
       "  0.6299982070922852,\n",
       "  0.6385582685470581,\n",
       "  0.6190268993377686,\n",
       "  0.6260812878608704,\n",
       "  0.6277178525924683,\n",
       "  0.622283935546875,\n",
       "  0.6132780313491821,\n",
       "  0.6166733503341675,\n",
       "  0.6194484829902649,\n",
       "  0.6176406741142273,\n",
       "  0.6326060891151428,\n",
       "  0.6275089979171753,\n",
       "  0.6137653589248657,\n",
       "  0.6187788844108582,\n",
       "  0.6161745190620422,\n",
       "  0.6077532768249512,\n",
       "  0.6204389333724976,\n",
       "  0.6143245100975037,\n",
       "  0.6279863119125366,\n",
       "  0.6047563552856445,\n",
       "  0.62306147813797,\n",
       "  0.6076730489730835,\n",
       "  0.6151086688041687,\n",
       "  0.609878420829773,\n",
       "  0.6213788390159607,\n",
       "  0.6188862323760986,\n",
       "  0.6092218160629272,\n",
       "  0.6022497415542603,\n",
       "  0.6304208636283875,\n",
       "  0.5963815450668335,\n",
       "  0.6146062016487122,\n",
       "  0.6179717183113098,\n",
       "  0.6021655201911926,\n",
       "  0.6156232357025146,\n",
       "  0.5926353335380554,\n",
       "  0.5990211963653564,\n",
       "  0.593015193939209,\n",
       "  0.6058152914047241,\n",
       "  0.6028765439987183,\n",
       "  0.5950760245323181,\n",
       "  0.6138789653778076,\n",
       "  0.6023572683334351,\n",
       "  0.6069602966308594,\n",
       "  0.5996020436286926,\n",
       "  0.600838303565979,\n",
       "  0.5939256548881531,\n",
       "  0.6103895306587219,\n",
       "  0.6030519604682922,\n",
       "  0.5981308221817017,\n",
       "  0.6060734987258911,\n",
       "  0.6086366176605225,\n",
       "  0.6066993474960327,\n",
       "  0.5955371260643005,\n",
       "  0.6003330945968628,\n",
       "  0.5939992070198059,\n",
       "  0.5823036432266235,\n",
       "  0.5984122157096863,\n",
       "  0.5906094312667847,\n",
       "  0.5954869985580444,\n",
       "  0.5861852169036865,\n",
       "  0.5806572437286377,\n",
       "  0.6050789952278137,\n",
       "  0.6098224520683289,\n",
       "  0.5953585505485535,\n",
       "  0.5969748497009277,\n",
       "  0.5860665440559387,\n",
       "  0.5800647139549255,\n",
       "  0.5967372059822083,\n",
       "  0.5893594026565552,\n",
       "  0.5892736911773682,\n",
       "  0.5863004922866821,\n",
       "  0.5869585275650024,\n",
       "  0.5909066200256348,\n",
       "  0.5847674608230591,\n",
       "  0.5856451392173767,\n",
       "  0.5757430195808411,\n",
       "  0.5963168740272522,\n",
       "  0.5783886313438416,\n",
       "  0.5815064907073975,\n",
       "  0.5842541456222534,\n",
       "  0.592023491859436,\n",
       "  0.5783593654632568,\n",
       "  0.5737311840057373,\n",
       "  0.5747944116592407,\n",
       "  0.5727208256721497,\n",
       "  0.5704395771026611,\n",
       "  0.5680650472640991,\n",
       "  0.5897600054740906,\n",
       "  0.5725669860839844],\n",
       " 'lambda_40_binary_accuracy': [0.6959459185600281,\n",
       "  0.7094594836235046,\n",
       "  0.7060810923576355,\n",
       "  0.6756756901741028,\n",
       "  0.6756756901741028,\n",
       "  0.7027027010917664,\n",
       "  0.6722972989082336,\n",
       "  0.7027027010917664,\n",
       "  0.6959459185600281,\n",
       "  0.712837815284729,\n",
       "  0.6925675868988037,\n",
       "  0.6891891956329346,\n",
       "  0.6689189076423645,\n",
       "  0.6993243098258972,\n",
       "  0.6959459185600281,\n",
       "  0.7162162065505981,\n",
       "  0.7060810923576355,\n",
       "  0.7635135054588318,\n",
       "  0.7263513803482056,\n",
       "  0.6959459185600281,\n",
       "  0.7263513803482056,\n",
       "  0.6858108043670654,\n",
       "  0.6824324131011963,\n",
       "  0.712837815284729,\n",
       "  0.6993243098258972,\n",
       "  0.7162162065505981,\n",
       "  0.7533783912658691,\n",
       "  0.7432432174682617,\n",
       "  0.7027027010917664,\n",
       "  0.6993243098258972,\n",
       "  0.7331081032752991,\n",
       "  0.6959459185600281,\n",
       "  0.7398648858070374,\n",
       "  0.7331081032752991,\n",
       "  0.7229729890823364,\n",
       "  0.6891891956329346,\n",
       "  0.6824324131011963,\n",
       "  0.7263513803482056,\n",
       "  0.7331081032752991,\n",
       "  0.712837815284729,\n",
       "  0.7567567825317383,\n",
       "  0.7263513803482056,\n",
       "  0.6993243098258972,\n",
       "  0.7297297120094299,\n",
       "  0.712837815284729,\n",
       "  0.7533783912658691,\n",
       "  0.7533783912658691,\n",
       "  0.7533783912658691,\n",
       "  0.7364864945411682,\n",
       "  0.75,\n",
       "  0.7432432174682617,\n",
       "  0.7094594836235046,\n",
       "  0.7297297120094299,\n",
       "  0.7466216087341309,\n",
       "  0.7398648858070374,\n",
       "  0.7635135054588318,\n",
       "  0.7364864945411682,\n",
       "  0.6959459185600281,\n",
       "  0.7162162065505981,\n",
       "  0.7195945978164673,\n",
       "  0.7668918967247009,\n",
       "  0.7162162065505981,\n",
       "  0.7331081032752991,\n",
       "  0.7263513803482056,\n",
       "  0.7331081032752991,\n",
       "  0.75,\n",
       "  0.7736486196517944,\n",
       "  0.7229729890823364,\n",
       "  0.7432432174682617,\n",
       "  0.7466216087341309,\n",
       "  0.7533783912658691,\n",
       "  0.7702702879905701,\n",
       "  0.7027027010917664,\n",
       "  0.7060810923576355,\n",
       "  0.7567567825317383,\n",
       "  0.7432432174682617,\n",
       "  0.7567567825317383,\n",
       "  0.7567567825317383,\n",
       "  0.7364864945411682,\n",
       "  0.7635135054588318,\n",
       "  0.7736486196517944,\n",
       "  0.7837837934494019,\n",
       "  0.7635135054588318,\n",
       "  0.7736486196517944,\n",
       "  0.7770270109176636,\n",
       "  0.7229729890823364,\n",
       "  0.8006756901741028,\n",
       "  0.7229729890823364,\n",
       "  0.7972972989082336,\n",
       "  0.7601351141929626,\n",
       "  0.7972972989082336,\n",
       "  0.7601351141929626,\n",
       "  0.7905405163764954,\n",
       "  0.7837837934494019,\n",
       "  0.7972972989082336,\n",
       "  0.7736486196517944,\n",
       "  0.8006756901741028,\n",
       "  0.787162184715271,\n",
       "  0.7601351141929626,\n",
       "  0.7736486196517944],\n",
       " 'total_loss': [5.619389057159424,\n",
       "  5.599818229675293,\n",
       "  5.607105255126953,\n",
       "  5.623719692230225,\n",
       "  5.615453720092773,\n",
       "  5.597567081451416,\n",
       "  5.6005048751831055,\n",
       "  5.598639488220215,\n",
       "  5.601625442504883,\n",
       "  5.5964789390563965,\n",
       "  5.596320152282715,\n",
       "  5.593539237976074,\n",
       "  5.597936630249023,\n",
       "  5.597372531890869,\n",
       "  5.596052169799805,\n",
       "  5.601770401000977,\n",
       "  5.603149890899658,\n",
       "  5.583117485046387,\n",
       "  5.583050727844238,\n",
       "  5.587308883666992,\n",
       "  5.5912933349609375,\n",
       "  5.601340293884277,\n",
       "  5.593934059143066,\n",
       "  5.585577011108398,\n",
       "  5.601840019226074,\n",
       "  5.580994606018066,\n",
       "  5.566763877868652,\n",
       "  5.583176612854004,\n",
       "  5.585689544677734,\n",
       "  5.623133659362793,\n",
       "  5.58004093170166,\n",
       "  5.59418249130249,\n",
       "  5.586794853210449,\n",
       "  5.578455924987793,\n",
       "  5.57960319519043,\n",
       "  5.574725151062012,\n",
       "  5.574212551116943,\n",
       "  5.575223445892334,\n",
       "  5.574674606323242,\n",
       "  5.592731475830078,\n",
       "  5.572271347045898,\n",
       "  5.564265727996826,\n",
       "  5.603239059448242,\n",
       "  5.574125289916992,\n",
       "  5.583093643188477,\n",
       "  5.563465118408203,\n",
       "  5.555755615234375,\n",
       "  5.5602569580078125,\n",
       "  5.5832014083862305,\n",
       "  5.580594062805176,\n",
       "  5.560502052307129,\n",
       "  5.58968448638916,\n",
       "  5.578000068664551,\n",
       "  5.5775861740112305,\n",
       "  5.582287788391113,\n",
       "  5.5707502365112305,\n",
       "  5.582655906677246,\n",
       "  5.588550567626953,\n",
       "  5.586251258850098,\n",
       "  5.562586784362793,\n",
       "  5.566174507141113,\n",
       "  5.596007823944092,\n",
       "  5.5817155838012695,\n",
       "  5.576780796051025,\n",
       "  5.567790508270264,\n",
       "  5.572639465332031,\n",
       "  5.553969383239746,\n",
       "  5.558348655700684,\n",
       "  5.570935249328613,\n",
       "  5.578229904174805,\n",
       "  5.54522705078125,\n",
       "  5.559596061706543,\n",
       "  5.584980010986328,\n",
       "  5.568046569824219,\n",
       "  5.565701961517334,\n",
       "  5.572214603424072,\n",
       "  5.567136287689209,\n",
       "  5.539424896240234,\n",
       "  5.553023338317871,\n",
       "  5.559463024139404,\n",
       "  5.555816173553467,\n",
       "  5.557685852050781,\n",
       "  5.5530219078063965,\n",
       "  5.570764541625977,\n",
       "  5.565274238586426,\n",
       "  5.553472518920898,\n",
       "  5.5413103103637695,\n",
       "  5.581179618835449,\n",
       "  5.54437255859375,\n",
       "  5.551947593688965,\n",
       "  5.5563459396362305,\n",
       "  5.572604179382324,\n",
       "  5.554080009460449,\n",
       "  5.543567180633545,\n",
       "  5.554075717926025,\n",
       "  5.55244255065918,\n",
       "  5.540550231933594,\n",
       "  5.547621726989746,\n",
       "  5.558981895446777,\n",
       "  5.541259288787842]}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "2bb643ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'lambda_41_loss', 'lambda_41_binary_accuracy']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f70acbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 467ms/step - loss: 0.6412 - lambda_41_loss: 0.6412 - lambda_41_binary_accuracy: 0.6622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6412062644958496, 0.6412062644958496, 0.662162184715271]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(train_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "99d465be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,f2 = m.predict(train_flow)\n",
    "\n",
    "y_pred = tf.sigmoid(tf.reduce_sum(f1 * f2, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "377dd4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(296,), dtype=float32, numpy=\n",
       "array([0.4214621 , 0.6343177 , 0.27815992, 0.42698175, 0.44059274,\n",
       "       0.6730277 , 0.5660984 , 0.32410556, 0.44542506, 0.4103326 ,\n",
       "       0.47371095, 0.3739282 , 0.32824227, 0.6641045 , 0.34755135,\n",
       "       0.6233138 , 0.52488905, 0.6447635 , 0.72807556, 0.58609617,\n",
       "       0.41524497, 0.682254  , 0.36021093, 0.49442458, 0.30711144,\n",
       "       0.36288166, 0.47647622, 0.693874  , 0.34530327, 0.65877324,\n",
       "       0.34600946, 0.36996993, 0.30104092, 0.52296144, 0.684875  ,\n",
       "       0.70588446, 0.6530269 , 0.2951056 , 0.6405028 , 0.6869508 ,\n",
       "       0.34783757, 0.32487962, 0.71315974, 0.43154207, 0.37801975,\n",
       "       0.5038921 , 0.3738873 , 0.703961  , 0.58637065, 0.6746161 ,\n",
       "       0.698067  , 0.3195354 , 0.6992749 , 0.29947665, 0.61251175,\n",
       "       0.3265617 , 0.39476448, 0.70040125, 0.40734494, 0.6986451 ,\n",
       "       0.46950603, 0.27972662, 0.30081362, 0.4478329 , 0.66195047,\n",
       "       0.4794958 , 0.31588942, 0.44720033, 0.36364594, 0.30069995,\n",
       "       0.34041363, 0.6752025 , 0.3862951 , 0.6979733 , 0.35225102,\n",
       "       0.56345445, 0.5828774 , 0.38218614, 0.5844532 , 0.7068771 ,\n",
       "       0.56019974, 0.3309856 , 0.30109736, 0.3598068 , 0.35412663,\n",
       "       0.6664044 , 0.37353748, 0.31077093, 0.5106207 , 0.7073657 ,\n",
       "       0.6852187 , 0.34355608, 0.68145347, 0.37257525, 0.5697085 ,\n",
       "       0.7133455 , 0.70437694, 0.31159353, 0.32113194, 0.6032256 ,\n",
       "       0.39904094, 0.34490755, 0.59833497, 0.4937121 , 0.35728174,\n",
       "       0.55820185, 0.66871196, 0.3507403 , 0.29838175, 0.36917302,\n",
       "       0.41693193, 0.5601326 , 0.63528126, 0.36076412, 0.6996122 ,\n",
       "       0.58939433, 0.32137433, 0.6711375 , 0.37382135, 0.39319515,\n",
       "       0.6774777 , 0.41048166, 0.6477078 , 0.40870637, 0.40892488,\n",
       "       0.6624247 , 0.5104341 , 0.61161   , 0.3033012 , 0.59249246,\n",
       "       0.42117533, 0.31796935, 0.6969726 , 0.66630185, 0.679898  ,\n",
       "       0.68086183, 0.68823254, 0.51179075, 0.60000974, 0.4458571 ,\n",
       "       0.40998277, 0.4390201 , 0.40219802, 0.382267  , 0.70289326,\n",
       "       0.3389204 , 0.42482477, 0.5131361 , 0.33428553, 0.29780644,\n",
       "       0.46921197, 0.6487254 , 0.3909648 , 0.61291516, 0.51204944,\n",
       "       0.5944909 , 0.4516657 , 0.6541435 , 0.623121  , 0.71915925,\n",
       "       0.6869362 , 0.34788066, 0.66988015, 0.45604625, 0.6089685 ,\n",
       "       0.3195027 , 0.68593097, 0.37177184, 0.42826927, 0.42560947,\n",
       "       0.63237876, 0.30788374, 0.5827986 , 0.5559221 , 0.7111831 ,\n",
       "       0.31923133, 0.41729796, 0.52028674, 0.6064378 , 0.49665385,\n",
       "       0.29827344, 0.6803612 , 0.3983458 , 0.58516645, 0.639622  ,\n",
       "       0.6767373 , 0.35119492, 0.40498692, 0.3141134 , 0.35960376,\n",
       "       0.68237734, 0.71823686, 0.69473654, 0.7128283 , 0.5001971 ,\n",
       "       0.61356664, 0.29586726, 0.5103808 , 0.54109484, 0.47120112,\n",
       "       0.5410196 , 0.46028468, 0.38837102, 0.7082478 , 0.35283458,\n",
       "       0.7231077 , 0.31687915, 0.38306832, 0.70427704, 0.32363054,\n",
       "       0.31895193, 0.3999668 , 0.58061403, 0.67259836, 0.3768885 ,\n",
       "       0.36545148, 0.30536532, 0.4443323 , 0.45126954, 0.55991656,\n",
       "       0.3182402 , 0.43185815, 0.27899757, 0.54641646, 0.33307374,\n",
       "       0.34584433, 0.336799  , 0.4960596 , 0.64806885, 0.44325846,\n",
       "       0.5706362 , 0.46079192, 0.3019683 , 0.32537147, 0.36531404,\n",
       "       0.42176953, 0.47974357, 0.7150766 , 0.32210496, 0.4057942 ,\n",
       "       0.58804846, 0.2970234 , 0.538536  , 0.6146387 , 0.30204827,\n",
       "       0.36720067, 0.33601448, 0.6875576 , 0.4790306 , 0.3913486 ,\n",
       "       0.2966824 , 0.6722622 , 0.6496709 , 0.70188683, 0.6837431 ,\n",
       "       0.6551171 , 0.64420164, 0.6683127 , 0.68344015, 0.3630675 ,\n",
       "       0.3634214 , 0.52103615, 0.3051601 , 0.36473882, 0.42524728,\n",
       "       0.5921357 , 0.434118  , 0.61737305, 0.6553215 , 0.36673108,\n",
       "       0.4105171 , 0.57032764, 0.38180846, 0.5805033 , 0.42033917,\n",
       "       0.40672678, 0.4966237 , 0.66752297, 0.70310825, 0.43538645,\n",
       "       0.38991275, 0.6875443 , 0.7170601 , 0.4556711 , 0.7164217 ,\n",
       "       0.67179435, 0.66980225, 0.62875307, 0.42355922, 0.37974045,\n",
       "       0.32402843, 0.3417048 , 0.6713686 , 0.677655  , 0.6610923 ,\n",
       "       0.36153743], dtype=float32)>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3dfa1d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "x_out [<tf.Tensor 'custom_model_35/lambda_36/l2_normalize_1:0' shape=(None, 8) dtype=float32>, <tf.Tensor 'custom_model_35/lambda_36/l2_normalize:0' shape=(None, 8) dtype=float32>]\n",
      "y_pred Tensor(\"Sigmoid:0\", shape=(None,), dtype=float32)\n",
      "x_out [<tf.Tensor 'custom_model_35/lambda_36/l2_normalize_1:0' shape=(None, 8) dtype=float32>, <tf.Tensor 'custom_model_35/lambda_36/l2_normalize:0' shape=(None, 8) dtype=float32>]\n",
      "y_pred Tensor(\"Sigmoid:0\", shape=(None,), dtype=float32)\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.7077 - lambda_36_loss: 0.7077 - lambda_36_binary_accuracy: 0.5034\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7055 - lambda_36_loss: 0.7055 - lambda_36_binary_accuracy: 0.5203\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7085 - lambda_36_loss: 0.7085 - lambda_36_binary_accuracy: 0.5304\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7081 - lambda_36_loss: 0.7081 - lambda_36_binary_accuracy: 0.5372\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6963 - lambda_36_loss: 0.6963 - lambda_36_binary_accuracy: 0.5270\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7052 - lambda_36_loss: 0.7052 - lambda_36_binary_accuracy: 0.5405\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7056 - lambda_36_loss: 0.7056 - lambda_36_binary_accuracy: 0.4899\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7117 - lambda_36_loss: 0.7117 - lambda_36_binary_accuracy: 0.5236\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7024 - lambda_36_loss: 0.7024 - lambda_36_binary_accuracy: 0.5236\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6869 - lambda_36_loss: 0.6869 - lambda_36_binary_accuracy: 0.5507\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7190 - lambda_36_loss: 0.7190 - lambda_36_binary_accuracy: 0.4797\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7038 - lambda_36_loss: 0.7038 - lambda_36_binary_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6809 - lambda_36_loss: 0.6809 - lambda_36_binary_accuracy: 0.5642\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6975 - lambda_36_loss: 0.6975 - lambda_36_binary_accuracy: 0.5338\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7052 - lambda_36_loss: 0.7052 - lambda_36_binary_accuracy: 0.4966\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6948 - lambda_36_loss: 0.6948 - lambda_36_binary_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6964 - lambda_36_loss: 0.6964 - lambda_36_binary_accuracy: 0.5338\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7039 - lambda_36_loss: 0.7039 - lambda_36_binary_accuracy: 0.4899\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6702 - lambda_36_loss: 0.6702 - lambda_36_binary_accuracy: 0.5845\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6807 - lambda_36_loss: 0.6807 - lambda_36_binary_accuracy: 0.5777\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6813 - lambda_36_loss: 0.6813 - lambda_36_binary_accuracy: 0.5608\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6902 - lambda_36_loss: 0.6902 - lambda_36_binary_accuracy: 0.5473\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6993 - lambda_36_loss: 0.6993 - lambda_36_binary_accuracy: 0.5034\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6930 - lambda_36_loss: 0.6930 - lambda_36_binary_accuracy: 0.5270\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6866 - lambda_36_loss: 0.6866 - lambda_36_binary_accuracy: 0.5473\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6795 - lambda_36_loss: 0.6795 - lambda_36_binary_accuracy: 0.5642\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6849 - lambda_36_loss: 0.6849 - lambda_36_binary_accuracy: 0.5338\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6879 - lambda_36_loss: 0.6879 - lambda_36_binary_accuracy: 0.5236\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6784 - lambda_36_loss: 0.6784 - lambda_36_binary_accuracy: 0.5574\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6904 - lambda_36_loss: 0.6904 - lambda_36_binary_accuracy: 0.5135\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6785 - lambda_36_loss: 0.6785 - lambda_36_binary_accuracy: 0.5676\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6833 - lambda_36_loss: 0.6833 - lambda_36_binary_accuracy: 0.5372\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6773 - lambda_36_loss: 0.6773 - lambda_36_binary_accuracy: 0.6149\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6831 - lambda_36_loss: 0.6831 - lambda_36_binary_accuracy: 0.5473\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6752 - lambda_36_loss: 0.6752 - lambda_36_binary_accuracy: 0.5642\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6660 - lambda_36_loss: 0.6660 - lambda_36_binary_accuracy: 0.6182\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6784 - lambda_36_loss: 0.6784 - lambda_36_binary_accuracy: 0.5777\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6825 - lambda_36_loss: 0.6825 - lambda_36_binary_accuracy: 0.5709\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6642 - lambda_36_loss: 0.6642 - lambda_36_binary_accuracy: 0.6284\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6751 - lambda_36_loss: 0.6751 - lambda_36_binary_accuracy: 0.5912\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6617 - lambda_36_loss: 0.6617 - lambda_36_binary_accuracy: 0.6047\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6679 - lambda_36_loss: 0.6679 - lambda_36_binary_accuracy: 0.5946\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6680 - lambda_36_loss: 0.6680 - lambda_36_binary_accuracy: 0.5743\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6640 - lambda_36_loss: 0.6640 - lambda_36_binary_accuracy: 0.5777\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6589 - lambda_36_loss: 0.6589 - lambda_36_binary_accuracy: 0.5912\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6685 - lambda_36_loss: 0.6685 - lambda_36_binary_accuracy: 0.6115\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6586 - lambda_36_loss: 0.6586 - lambda_36_binary_accuracy: 0.6250\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6501 - lambda_36_loss: 0.6501 - lambda_36_binary_accuracy: 0.6689\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6622 - lambda_36_loss: 0.6622 - lambda_36_binary_accuracy: 0.6182\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6584 - lambda_36_loss: 0.6584 - lambda_36_binary_accuracy: 0.6385\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6568 - lambda_36_loss: 0.6568 - lambda_36_binary_accuracy: 0.6081\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6615 - lambda_36_loss: 0.6615 - lambda_36_binary_accuracy: 0.6250\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6590 - lambda_36_loss: 0.6590 - lambda_36_binary_accuracy: 0.6182\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6487 - lambda_36_loss: 0.6487 - lambda_36_binary_accuracy: 0.6588\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6522 - lambda_36_loss: 0.6522 - lambda_36_binary_accuracy: 0.6149\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6598 - lambda_36_loss: 0.6598 - lambda_36_binary_accuracy: 0.6047\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.6590 - lambda_36_loss: 0.6590 - lambda_36_binary_accuracy: 0.6081\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6532 - lambda_36_loss: 0.6532 - lambda_36_binary_accuracy: 0.6081\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6539 - lambda_36_loss: 0.6539 - lambda_36_binary_accuracy: 0.6520\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6684 - lambda_36_loss: 0.6684 - lambda_36_binary_accuracy: 0.6115\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6529 - lambda_36_loss: 0.6529 - lambda_36_binary_accuracy: 0.6216\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6561 - lambda_36_loss: 0.6561 - lambda_36_binary_accuracy: 0.6149\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6500 - lambda_36_loss: 0.6500 - lambda_36_binary_accuracy: 0.6453\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6607 - lambda_36_loss: 0.6607 - lambda_36_binary_accuracy: 0.6182\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6547 - lambda_36_loss: 0.6547 - lambda_36_binary_accuracy: 0.6419\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6488 - lambda_36_loss: 0.6488 - lambda_36_binary_accuracy: 0.6385\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6430 - lambda_36_loss: 0.6430 - lambda_36_binary_accuracy: 0.6622\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6389 - lambda_36_loss: 0.6389 - lambda_36_binary_accuracy: 0.6892\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6429 - lambda_36_loss: 0.6429 - lambda_36_binary_accuracy: 0.6723\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6452 - lambda_36_loss: 0.6452 - lambda_36_binary_accuracy: 0.6554\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6482 - lambda_36_loss: 0.6482 - lambda_36_binary_accuracy: 0.6486\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6412 - lambda_36_loss: 0.6412 - lambda_36_binary_accuracy: 0.6622\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6522 - lambda_36_loss: 0.6522 - lambda_36_binary_accuracy: 0.6284\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6471 - lambda_36_loss: 0.6471 - lambda_36_binary_accuracy: 0.6453\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6370 - lambda_36_loss: 0.6370 - lambda_36_binary_accuracy: 0.6858\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6630 - lambda_36_loss: 0.6630 - lambda_36_binary_accuracy: 0.6081\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6361 - lambda_36_loss: 0.6361 - lambda_36_binary_accuracy: 0.6554\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6494 - lambda_36_loss: 0.6494 - lambda_36_binary_accuracy: 0.6520\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6573 - lambda_36_loss: 0.6573 - lambda_36_binary_accuracy: 0.6149\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6288 - lambda_36_loss: 0.6288 - lambda_36_binary_accuracy: 0.7027\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6251 - lambda_36_loss: 0.6251 - lambda_36_binary_accuracy: 0.7230\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6443 - lambda_36_loss: 0.6443 - lambda_36_binary_accuracy: 0.6892\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6396 - lambda_36_loss: 0.6396 - lambda_36_binary_accuracy: 0.6689\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6389 - lambda_36_loss: 0.6389 - lambda_36_binary_accuracy: 0.6757\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6395 - lambda_36_loss: 0.6395 - lambda_36_binary_accuracy: 0.6689\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6419 - lambda_36_loss: 0.6419 - lambda_36_binary_accuracy: 0.6419\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6518 - lambda_36_loss: 0.6518 - lambda_36_binary_accuracy: 0.6351\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6288 - lambda_36_loss: 0.6288 - lambda_36_binary_accuracy: 0.6993\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6436 - lambda_36_loss: 0.6436 - lambda_36_binary_accuracy: 0.6554\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6384 - lambda_36_loss: 0.6384 - lambda_36_binary_accuracy: 0.6554\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6296 - lambda_36_loss: 0.6296 - lambda_36_binary_accuracy: 0.7027\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6359 - lambda_36_loss: 0.6359 - lambda_36_binary_accuracy: 0.6757\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6340 - lambda_36_loss: 0.6340 - lambda_36_binary_accuracy: 0.6858\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6358 - lambda_36_loss: 0.6358 - lambda_36_binary_accuracy: 0.6892\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6215 - lambda_36_loss: 0.6215 - lambda_36_binary_accuracy: 0.7230\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6267 - lambda_36_loss: 0.6267 - lambda_36_binary_accuracy: 0.6858\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6337 - lambda_36_loss: 0.6337 - lambda_36_binary_accuracy: 0.7095\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6342 - lambda_36_loss: 0.6342 - lambda_36_binary_accuracy: 0.6791\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6233 - lambda_36_loss: 0.6233 - lambda_36_binary_accuracy: 0.7162\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6317 - lambda_36_loss: 0.6317 - lambda_36_binary_accuracy: 0.6791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2cad0d978>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(train_flow, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.binary_crossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f03e6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58e95e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = m.predict(train_flow)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1047d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = next(iter(train_flow))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "cff4dc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 1)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "4f1b29f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(296, 1), dtype=bool, numpy=\n",
       "array([[False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.greater(out, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "1dff6c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5033784"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.cast(tf.where(tf.greater(y_pred, 0.5), 1,0) == ans, dtype = tf.float32)).numpy()\n",
    "\n",
    "\n",
    "\n",
    "#dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "8a6066cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c922f950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76159155963922"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "-np.log(0.4669227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2792c7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.70340556>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce = losses.BinaryCrossentropy()\n",
    "\n",
    "bce(ans, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b77ebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.70340556>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(losses.binary_crossentropy(ans, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3b59665",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 857324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7e5b426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May  5 12:18:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 47%   50C    P2   136W / 370W |   3012MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "|  0%   42C    P8    16W / 370W |    820MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 29%   51C    P8    18W / 250W |    512MiB / 11176MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    856513      C   ...3/envs/hinsage/bin/python     1479MiB |\n",
      "|    0   N/A  N/A    872710      C   ...3/envs/hinsage/bin/python     1531MiB |\n",
      "|    1   N/A  N/A    856513      C   ...3/envs/hinsage/bin/python      409MiB |\n",
      "|    1   N/A  N/A    872710      C   ...3/envs/hinsage/bin/python      409MiB |\n",
      "|    2   N/A  N/A    856513      C   ...3/envs/hinsage/bin/python      255MiB |\n",
      "|    2   N/A  N/A    872710      C   ...3/envs/hinsage/bin/python      255MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b59f386",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'value_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-32657bf0503a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'value_index'"
     ]
    }
   ],
   "source": [
    "tf.Ten(100, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cf8b2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=[100,8])\n",
    "b = tf.random.uniform(shape=[100,8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ad3d3659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "array([0.9274587 , 0.90024555, 0.85716206, 0.9229575 , 0.8825929 ,\n",
       "       0.9325966 , 0.83515495, 0.86315465, 0.8742881 , 0.9454551 ,\n",
       "       0.69056845, 0.8728952 , 0.9004553 , 0.86446416, 0.8639686 ,\n",
       "       0.94796664, 0.8146889 , 0.82676065, 0.9080979 , 0.8369695 ,\n",
       "       0.86435014, 0.8274217 , 0.8720906 , 0.8410847 , 0.8055149 ,\n",
       "       0.7882754 , 0.7038872 , 0.7821462 , 0.9296208 , 0.8763036 ,\n",
       "       0.94411826, 0.87179303, 0.86665726, 0.9305248 , 0.9025456 ,\n",
       "       0.96157837, 0.90750384, 0.8662    , 0.84439236, 0.9218731 ,\n",
       "       0.9219297 , 0.78211206, 0.85409033, 0.73812324, 0.8395197 ,\n",
       "       0.9274993 , 0.65730447, 0.9389467 , 0.7053751 , 0.8782381 ,\n",
       "       0.959176  , 0.8000171 , 0.9173149 , 0.87295604, 0.7789003 ,\n",
       "       0.89327157, 0.90504247, 0.7566486 , 0.8696951 , 0.81077003,\n",
       "       0.8918264 , 0.9026918 , 0.7887758 , 0.93749064, 0.9358661 ,\n",
       "       0.9529474 , 0.8053031 , 0.8728163 , 0.94913363, 0.7705759 ,\n",
       "       0.92667574, 0.87427545, 0.8868529 , 0.8056607 , 0.818618  ,\n",
       "       0.86749685, 0.9527981 , 0.83596295, 0.87881017, 0.93968403,\n",
       "       0.93992925, 0.87613946, 0.7566679 , 0.78075576, 0.902575  ,\n",
       "       0.90179133, 0.917272  , 0.9089733 , 0.9484289 , 0.8979901 ,\n",
       "       0.70113033, 0.9195371 , 0.89296746, 0.9372802 , 0.8640961 ,\n",
       "       0.8408783 , 0.88466364, 0.81501585, 0.9496841 , 0.9452168 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sigmoid(tf.reduce_sum(a * b, axis = 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
