{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ccc6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gyuseok/anaconda3/envs/hinsage/lib/python3.6/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_content_from_url(url:str):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65076f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end(a_tags):\n",
    "\n",
    "    start_idx = None\n",
    "    end_idx = None\n",
    "\n",
    "    for idx, l in enumerate(a_tags):\n",
    "        if start_idx is None and str(l).find(\"Boolean retrieval\") > 0:\n",
    "            start_idx = idx\n",
    "\n",
    "        if end_idx is None and str(l).find(\"Link analysis\") > 0:\n",
    "            end_idx = idx\n",
    "    return (start_idx, end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5a2e07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_context_url(tag : bs4.element.Tag,\n",
    "                    base_url : str\n",
    "                    )-> tuple():\n",
    "    \n",
    "    contents = tag.text\n",
    "    tag = str(tag)\n",
    "    \n",
    "    link_start = tag.find(\"href\")\n",
    "    link_end = tag.find(\"html\")\n",
    "    url = tag[link_start + 6 : link_end + 4]\n",
    "    \n",
    "    url = base_url.split(\"/\")[:-1] + [url]\n",
    "    url = \"/\".join(url)\n",
    "    \n",
    "    return (contents, url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e87d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_context(content:str):\n",
    "    content = \" \".join(content.split())\n",
    "    content = re.sub(r\"[^0-9a-zA-Z\\s]\", \"\", content)\n",
    "    return content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085c985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Boolean retrieval', 'https://nlp.stanford.edu/IR-book/html/htmledition/boolean-retrieval-1.html')\n"
     ]
    }
   ],
   "source": [
    "# base\n",
    "base_url = \"https://nlp.stanford.edu/IR-book/html/htmledition/irbook.html\"\n",
    "soup = get_content_from_url(base_url)\n",
    "a_tags = soup.find_all(\"a\")\n",
    "\n",
    "\n",
    "# target\n",
    "start_idx, end_idx = get_start_end(a_tags)\n",
    "target_tags = a_tags[start_idx : end_idx + 1]\n",
    "target_context_url = list(map(lambda x: get_context_url(x, base_url), target_tags))\n",
    "\n",
    "print(target_context_url[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c2e0a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keyword\n",
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "results = {}\n",
    "for chapter, url in target_context_url:\n",
    "    content = get_content_from_url(url).text\n",
    "    content = clear_context(content)\n",
    "    \n",
    "    # get keywrods\n",
    "    keywords = kw_model.extract_keywords(content, top_n = 10)\n",
    "    keywords = list(map(lambda x: x[0], keywords))\n",
    "    \n",
    "    # save\n",
    "    results[chapter] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c2cbc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Boolean retrieval',\n",
       "  'The term vocabulary and postings lists',\n",
       "  'Dictionaries and tolerant retrieval',\n",
       "  'Index construction',\n",
       "  'Index compression',\n",
       "  'Scoring, term weighting and the vector space model',\n",
       "  'Computing scores in a complete search system',\n",
       "  'Evaluation in information retrieval',\n",
       "  'Relevance feedback and query expansion',\n",
       "  'XML retrieval',\n",
       "  'Probabilistic information retrieval',\n",
       "  'Language models for information retrieval',\n",
       "  'Text classification and Naive Bayes',\n",
       "  'Vector space classification',\n",
       "  'Support vector machines and machine learning on documents',\n",
       "  'Flat clustering',\n",
       "  'Hierarchical clustering',\n",
       "  'Matrix decompositions and latent semantic indexing',\n",
       "  'Web search basics',\n",
       "  'Web crawling and indexes',\n",
       "  'Link analysis'],\n",
       " [['retrieval',\n",
       "   'information',\n",
       "   'documents',\n",
       "   'searching',\n",
       "   'queries',\n",
       "   'searchers',\n",
       "   'search',\n",
       "   'data',\n",
       "   'indexing',\n",
       "   'database'],\n",
       "  ['tokenization',\n",
       "   'indexing',\n",
       "   'indexes',\n",
       "   'linguistic',\n",
       "   'stemming',\n",
       "   'documents',\n",
       "   'vocabulary',\n",
       "   'diacritics',\n",
       "   'tokenize',\n",
       "   'document'],\n",
       "  ['retrieval',\n",
       "   'dictionaries',\n",
       "   'searching',\n",
       "   'search',\n",
       "   'queries',\n",
       "   'indexes',\n",
       "   'spellings',\n",
       "   'vowels',\n",
       "   'vocabulary',\n",
       "   'spell'],\n",
       "  ['indexing',\n",
       "   'indexers',\n",
       "   'indexes',\n",
       "   'indexer',\n",
       "   'index',\n",
       "   'retrieval',\n",
       "   'collections',\n",
       "   'crawled',\n",
       "   'sortbased',\n",
       "   'hardware'],\n",
       "  ['compression',\n",
       "   'compressed',\n",
       "   'retrieval',\n",
       "   'decompressing',\n",
       "   'compressing',\n",
       "   'decompression',\n",
       "   'storage',\n",
       "   'memory',\n",
       "   'compress',\n",
       "   'caching'],\n",
       "  ['ranking',\n",
       "   'indexes',\n",
       "   'index',\n",
       "   'termweighting',\n",
       "   'search',\n",
       "   'documents',\n",
       "   'queries',\n",
       "   'scores',\n",
       "   'rankorder',\n",
       "   'topics'],\n",
       "  ['ranking',\n",
       "   'indexes',\n",
       "   'retrieval',\n",
       "   'search',\n",
       "   'queries',\n",
       "   'scores',\n",
       "   'index',\n",
       "   'heuristics',\n",
       "   'queryterm',\n",
       "   'scoring'],\n",
       "  ['retrieval',\n",
       "   'ranking',\n",
       "   'evaluation',\n",
       "   'evaluating',\n",
       "   'relevance',\n",
       "   'ranked',\n",
       "   'irbook',\n",
       "   'effectiveness',\n",
       "   'documents',\n",
       "   'index'],\n",
       "  ['retrieval',\n",
       "   'relevance',\n",
       "   'thesaurus',\n",
       "   'search',\n",
       "   'wordnet',\n",
       "   'refinement',\n",
       "   'vocabulary',\n",
       "   'refining',\n",
       "   'terms',\n",
       "   'query'],\n",
       "  ['retrieval',\n",
       "   'querying',\n",
       "   'xml',\n",
       "   'databases',\n",
       "   'queries',\n",
       "   'xquery',\n",
       "   'database',\n",
       "   'sql',\n",
       "   'documents',\n",
       "   'search'],\n",
       "  ['retrieval',\n",
       "   'relevance',\n",
       "   'probabilistic',\n",
       "   'documents',\n",
       "   'information',\n",
       "   'document',\n",
       "   'irbook',\n",
       "   'classifier',\n",
       "   'ranking',\n",
       "   'content'],\n",
       "  ['retrieval',\n",
       "   'ranking',\n",
       "   'queries',\n",
       "   'documents',\n",
       "   'language',\n",
       "   'relevance',\n",
       "   'document',\n",
       "   'irbook',\n",
       "   'models',\n",
       "   'probabilistic'],\n",
       "  ['retrieval',\n",
       "   'indexing',\n",
       "   'searches',\n",
       "   'queries',\n",
       "   'searching',\n",
       "   'search',\n",
       "   'incrementally',\n",
       "   'classification',\n",
       "   'stemming',\n",
       "   'microprocessor'],\n",
       "  ['classifying',\n",
       "   'classification',\n",
       "   'classify',\n",
       "   'classifiers',\n",
       "   'documents',\n",
       "   'classes',\n",
       "   'document',\n",
       "   'relatedness',\n",
       "   'patterns',\n",
       "   'hyperplanes'],\n",
       "  ['classifiers',\n",
       "   'classifier',\n",
       "   'svm',\n",
       "   'svms',\n",
       "   'classification',\n",
       "   'machinelearning',\n",
       "   'ranking',\n",
       "   'classes',\n",
       "   'features',\n",
       "   'retrieval'],\n",
       "  ['clusterings',\n",
       "   'clustering',\n",
       "   'clusters',\n",
       "   'cluster',\n",
       "   'unsupervised',\n",
       "   'classification',\n",
       "   'supervised',\n",
       "   'retrieval',\n",
       "   'hierarchical',\n",
       "   'documents'],\n",
       "  ['clusteringhierarchical',\n",
       "   'clusters',\n",
       "   'hierarchical',\n",
       "   'cluster',\n",
       "   'hierarchy',\n",
       "   'clustering',\n",
       "   'hierarchic',\n",
       "   'agglomerative',\n",
       "   'algorithms',\n",
       "   'unstructured'],\n",
       "  ['indexing',\n",
       "   'retrieval',\n",
       "   'matrices',\n",
       "   'ranking',\n",
       "   'matrix',\n",
       "   'index',\n",
       "   'termdocument',\n",
       "   'lowrank',\n",
       "   'semantic',\n",
       "   'documents'],\n",
       "  ['indexes',\n",
       "   'search',\n",
       "   'retrieval',\n",
       "   'indexed',\n",
       "   'web',\n",
       "   'index',\n",
       "   'collections',\n",
       "   'basics',\n",
       "   'documents',\n",
       "   'information'],\n",
       "  ['crawler',\n",
       "   'indexes',\n",
       "   'crawling',\n",
       "   'index',\n",
       "   'web',\n",
       "   'dns',\n",
       "   'page',\n",
       "   'contents',\n",
       "   'servers',\n",
       "   'overview'],\n",
       "  ['pagerank',\n",
       "   'citations',\n",
       "   'bibliometrics',\n",
       "   'hyperlinks',\n",
       "   'hyperlink',\n",
       "   'citation',\n",
       "   'scholarly',\n",
       "   'ranking',\n",
       "   'inlinks',\n",
       "   'references']])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(results.keys()), list(results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "309aabcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csv_file</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boolean retrieval</td>\n",
       "      <td>[retrieval, information, documents, searching,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The term vocabulary and postings lists</td>\n",
       "      <td>[tokenization, indexing, indexes, linguistic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dictionaries and tolerant retrieval</td>\n",
       "      <td>[retrieval, dictionaries, searching, search, q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Index construction</td>\n",
       "      <td>[indexing, indexers, indexes, indexer, index, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Index compression</td>\n",
       "      <td>[compression, compressed, retrieval, decompres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 csv_file  \\\n",
       "0                       Boolean retrieval   \n",
       "1  The term vocabulary and postings lists   \n",
       "2     Dictionaries and tolerant retrieval   \n",
       "3                      Index construction   \n",
       "4                       Index compression   \n",
       "\n",
       "                                            keywords  \n",
       "0  [retrieval, information, documents, searching,...  \n",
       "1  [tokenization, indexing, indexes, linguistic, ...  \n",
       "2  [retrieval, dictionaries, searching, search, q...  \n",
       "3  [indexing, indexers, indexes, indexer, index, ...  \n",
       "4  [compression, compressed, retrieval, decompres...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"csv_file\" : list(results.keys()), \"keywords\" : list(results.values())})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e050902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Stanford_NLP_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2b82d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " Bert.ipynb\n",
      " Concept-Extraction\n",
      " content.csv\n",
      " correlations.csv\n",
      " csv2wiki.pickle\n",
      " csv_dict.pickle\n",
      " csv_keywords_df.csv\n",
      " csv_wiki_graph\n",
      " csv_wiki_graph.pickle\n",
      " data.pickle\n",
      " Deepwalk.ipynb\n",
      " Deepwalk_practice.ipynb\n",
      " Embedding\n",
      " embedding.pickle\n",
      "'(Final)Linkprediction.ipynb'\n",
      " gyuseok\n",
      " Kaggle.ipynb\n",
      " learning-equality-curriculum-recommendations.zip\n",
      " Link_Prediction2.ipynb\n",
      " LinkPrediction3.ipynb\n",
      " Link_Prediction.ipynb\n",
      " MetaPath2Vec.ipynb\n",
      " Preprocess.ipynb\n",
      " python\n",
      " sample_submission.csv\n",
      " Spider\n",
      " Stanford_NLP_df.csv\n",
      " topics.csv\n",
      " Untitled1.ipynb\n",
      " Untitled2.ipynb\n",
      " Untitled.ipynb\n",
      " video2graph.ipynb\n",
      " WebScraper.ipynb\n",
      " weighted_link_prediction.ipynb\n",
      " wiki2csv.pickle\n",
      " wiki_dict.pickle\n",
      " Wikipedia.ipynb\n",
      " Wikipedia.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2ec1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
